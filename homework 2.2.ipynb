{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89615ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold \n",
    "from sklearn.model_selection import cross_val_score \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import datasets\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ada1203a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis(1=m, 0=b)</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   diagnosis(1=m, 0=b)  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0                    1        17.99         10.38          122.80     1001.0   \n",
       "1                    1        20.57         17.77          132.90     1326.0   \n",
       "2                    1        19.69         21.25          130.00     1203.0   \n",
       "3                    1        11.42         20.38           77.58      386.1   \n",
       "4                    1        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
       "0         0.2419  ...         25.38          17.33           184.60   \n",
       "1         0.1812  ...         24.99          23.41           158.80   \n",
       "2         0.2069  ...         23.57          25.53           152.50   \n",
       "3         0.2597  ...         14.91          26.50            98.87   \n",
       "4         0.1809  ...         22.54          16.67           152.20   \n",
       "\n",
       "   area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0      2019.0            0.1622             0.6656           0.7119   \n",
       "1      1956.0            0.1238             0.1866           0.2416   \n",
       "2      1709.0            0.1444             0.4245           0.4504   \n",
       "3       567.7            0.2098             0.8663           0.6869   \n",
       "4      1575.0            0.1374             0.2050           0.4000   \n",
       "\n",
       "   concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "0                0.2654          0.4601                  0.11890  \n",
       "1                0.1860          0.2750                  0.08902  \n",
       "2                0.2430          0.3613                  0.08758  \n",
       "3                0.2575          0.6638                  0.17300  \n",
       "4                0.1625          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df =pd.read_csv('https://gist.githubusercontent.com/KhanradCoder/35a6beea49e5b9ba62797e595a9626c0/raw/8974e055bdf3a9d7e6cacf1c1c30fcfd2ffd6de3/cancer.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c587ab46",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:, 1:30].values \n",
    "Y = df.iloc[:, 0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6faca940",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3c9c809",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler \n",
    "sc_X = StandardScaler() \n",
    "X_train = sc_X.fit_transform(X_train) \n",
    "X_test = sc_X.transform(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a0f5e6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression \n",
    "classifier = LogisticRegression(random_state=0) \n",
    "classifier.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a1d3ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = classifier.predict(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d1c0e258",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[70,  1],\n",
       "       [ 1, 42]], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix \n",
    "cnf_matrix = confusion_matrix(Y_test, Y_pred) \n",
    "cnf_matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "235b5a5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9824561403508771\n",
      "Precision: 0.9767441860465116\n",
      "Recall: 0.9767441860465116\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics \n",
    "print(\"Accuracy:\",metrics.accuracy_score(Y_test, Y_pred)) \n",
    "print(\"Precision:\",metrics.precision_score(Y_test, Y_pred)) \n",
    "print(\"Recall:\",metrics.recall_score(Y_test, Y_pred)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5fae25eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 257.44, 'Predicted label')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns \n",
    "class_names=[0,1] # name  of classes \n",
    "fig, ax = plt.subplots() \n",
    "tick_marks = np.arange(len(class_names)) \n",
    "plt.xticks(tick_marks, class_names) \n",
    "plt.yticks(tick_marks, class_names) \n",
    "# create heatmap \n",
    "sns.heatmap(pd.DataFrame(cnf_matrix), annot=True, cmap=\"YlGnBu\" ,fmt='g') \n",
    "ax.xaxis.set_label_position(\"top\") \n",
    "plt.tight_layout() \n",
    "plt.title('Confusion matrix', y=1.1) \n",
    "plt.ylabel('Actual label') \n",
    "plt.xlabel('Predicted label') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1624a0a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 95.434% (2.737%)\n"
     ]
    }
   ],
   "source": [
    "# 5 folds selected\n",
    "kfold = KFold (n_splits=5, random_state=0, shuffle=True)\n",
    "model = LogisticRegression (solver='liblinear')\n",
    "results = cross_val_score (model, X, Y, cv=kfold)\n",
    "# Output the accuracy. Calculate the mean and std across all folds. \n",
    "print(\"Accuracy: %.3f%% (%.3f%%)\" % (results.mean()*100.0, results.std()*100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fe866225",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 95.432% (3.858%)\n"
     ]
    }
   ],
   "source": [
    "kfold = KFold (n_splits=10, random_state=0, shuffle=True)\n",
    "model = LogisticRegression (solver='liblinear')\n",
    "results = cross_val_score (model, X, Y, cv=kfold)\n",
    "# Output the accuracy. Calculate the mean and std across all folds. \n",
    "print(\"Accuracy: %.3f%% (%.3f%%)\" % (results.mean()*100.0, results.std()*100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6ce0faa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[63  4]\n",
      " [ 1 46]]\n"
     ]
    }
   ],
   "source": [
    "# Construct a confusion matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "test_size = 0.2\n",
    "seed = 0\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size,random_state=seed)\n",
    "model = LogisticRegression (solver='liblinear')\n",
    "model.fit(X_train, Y_train)\n",
    "predicted = model.predict(X_test)\n",
    "matrix = confusion_matrix (Y_test, predicted) \n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1af0af0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C: 10\n",
      "Training accuracy: 0.9758241758241758\n",
      "Test accuracy: 0.9649122807017544\n",
      " \n",
      "C: 1\n",
      "Training accuracy: 0.9626373626373627\n",
      "Test accuracy: 0.956140350877193\n",
      " \n",
      "C: 0.1\n",
      "Training accuracy: 0.9406593406593406\n",
      "Test accuracy: 0.9385964912280702\n",
      " \n",
      "C: 0.001\n",
      "Training accuracy: 0.9164835164835164\n",
      "Test accuracy: 0.9122807017543859\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bharath Kumar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    }
   ],
   "source": [
    "C= [10, 1, .1, .001]\n",
    "\n",
    "for c in C:\n",
    "    clf=LogisticRegression (penalty='l1', C=c, solver='liblinear')\n",
    "    clf.fit(X_train, Y_train)\n",
    "    print('C:', c)\n",
    "    print('Training accuracy:', clf.score (X_train, Y_train)) \n",
    "    print('Test accuracy:', clf.score (X_test, Y_test)) \n",
    "    print(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "edb0c272",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bharath Kumar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 96.313% (1.951%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bharath Kumar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\Bharath Kumar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\Bharath Kumar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\Bharath Kumar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 95.609% (2.658%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bharath Kumar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\Bharath Kumar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 92.972% (3.232%)\n",
      "Accuracy: 91.388% (2.797%)\n"
     ]
    }
   ],
   "source": [
    "C= [10, 1, .1, .001]\n",
    "\n",
    "for c in C:\n",
    "    kfold = KFold (n_splits=5, random_state=0, shuffle=True)\n",
    "    clf=LogisticRegression (penalty='l1', C=c, solver='liblinear')\n",
    "    results = cross_val_score (clf, X, Y, cv=kfold)\n",
    "    print(\"Accuracy: %.3f%% (%.3f%%)\" % (results.mean()*100.0, results.std()*100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e75fee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
